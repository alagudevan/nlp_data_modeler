{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper 2 Data Workflow for Data Extraction - CUADv1 - Pre-Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijay/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/vijay/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import the various libraries\n",
    "import re, json, os, itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. File handling - CUADv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to each individual txt files converted from PDF\n",
    "TC_PATH = \"CUAD-v1/full_contract_txt/\"\n",
    "\n",
    "# Path to folder containing all the CUAD data and files\n",
    "MASTER_PATH = \"CUAD-v1/\"\n",
    "\n",
    "# Name of CSV file containing all the extracted clauses from the Atticus team\n",
    "MASTER_CLAUSES = 'master_clauses.csv'\n",
    "\n",
    "# Name of JSON file to export the agreement text and labels for data extraction\n",
    "JSON_EXPORT = 'jsonl_cuadv1.json'\n",
    "\n",
    "# Name of JSON file to export the agreement taxt and labels for further inspection\n",
    "JSON_EXPORT_INSPECT = 'jsonl_cuadv1_inspect.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text Data Preprocessing - CUADv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ThemartComInc_19990826_10-12G_EX-10.10_670028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCURAYINC_09_01_2010-EX-10.31-DISTRIBUTOR AGR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADAMSGOLFINC_03_21_2005-EX-10.17-ENDORSEMENT A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Files\n",
       "0  2ThemartComInc_19990826_10-12G_EX-10.10_670028...\n",
       "1  ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEME...\n",
       "2  ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-...\n",
       "3  ACCURAYINC_09_01_2010-EX-10.31-DISTRIBUTOR AGR...\n",
       "4  ADAMSGOLFINC_03_21_2005-EX-10.17-ENDORSEMENT A..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Walk through all .txt filenames and create a dataframe with the names of the files, sorted alpha/num\n",
    "text_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(TC_PATH):\n",
    "    text_files.extend(filenames)\n",
    "\n",
    "tf_df = pd.DataFrame(data = text_files, columns = ['Text Files'])\n",
    "tf_df.sort_values('Text Files', axis=0, inplace=True, ignore_index=True) \n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Document Name</th>\n",
       "      <th>Document Name-Answer</th>\n",
       "      <th>Parties</th>\n",
       "      <th>Parties-Answer</th>\n",
       "      <th>Agreement Date</th>\n",
       "      <th>Agreement Date-Answer</th>\n",
       "      <th>Effective Date</th>\n",
       "      <th>Effective Date-Answer</th>\n",
       "      <th>Expiration Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Liquidated Damages</th>\n",
       "      <th>Liquidated Damages-Answer</th>\n",
       "      <th>Warranty Duration</th>\n",
       "      <th>Warranty Duration-Answer</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Insurance-Answer</th>\n",
       "      <th>Covenant Not To Sue</th>\n",
       "      <th>Covenant Not To Sue-Answer</th>\n",
       "      <th>Third Party Beneficiary</th>\n",
       "      <th>Third Party Beneficiary-Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...</td>\n",
       "      <td>['MARKETING AFFILIATE AGREEMENT']</td>\n",
       "      <td>MARKETING AFFILIATE AGREEMENT</td>\n",
       "      <td>['BIRCH FIRST GLOBAL INVESTMENTS INC.', 'MA', ...</td>\n",
       "      <td>Birch First Global Investments Inc. (\"Company\"...</td>\n",
       "      <td>['8th day of May 2014', 'May 8, 2014']</td>\n",
       "      <td>5/8/14</td>\n",
       "      <td>['This agreement shall begin upon the date of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['This agreement shall begin upon the date of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[\"COMPANY'S SOLE AND EXCLUSIVE LIABILITY FOR T...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...</td>\n",
       "      <td>['VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT']</td>\n",
       "      <td>VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT</td>\n",
       "      <td>['EuroMedia Holdings Corp.', 'Rogers', 'Rogers...</td>\n",
       "      <td>Rogers Cable Communications Inc. (\"Rogers\"); E...</td>\n",
       "      <td>['July 11 , 2006']</td>\n",
       "      <td>7/11/06</td>\n",
       "      <td>['July 11 , 2006']</td>\n",
       "      <td>7/11/06</td>\n",
       "      <td>['The term of this Agreement (the \"Initial Ter...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...</td>\n",
       "      <td>['CONTENT DISTRIBUTION AND LICENSE AGREEMENT']</td>\n",
       "      <td>CONTENT DISTRIBUTION AND LICENSE AGREEMENT</td>\n",
       "      <td>['Producer', 'Fulucai Productions Ltd.', 'Conv...</td>\n",
       "      <td>CONVERGTV, INC. (“ConvergTV”); Fulucai Product...</td>\n",
       "      <td>['November 15, 2012']</td>\n",
       "      <td>11/15/12</td>\n",
       "      <td>['November 15, 2012']</td>\n",
       "      <td>11/15/12</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...</td>\n",
       "      <td>['WEBSITE CONTENT LICENSE AGREEMENT']</td>\n",
       "      <td>WEBSITE CONTENT LICENSE AGREEMENT</td>\n",
       "      <td>['PSiTech Corporation', 'Licensor', 'Licensee'...</td>\n",
       "      <td>PSiTech Corporation (\"Licensor\"); Empirical Ve...</td>\n",
       "      <td>['Feb 10, 2014']</td>\n",
       "      <td>2/10/14</td>\n",
       "      <td>['Feb 10, 2014']</td>\n",
       "      <td>2/10/14</td>\n",
       "      <td>['The initial term of this Agreement commences...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...</td>\n",
       "      <td>['CONTENT LICENSE AGREEMENT']</td>\n",
       "      <td>CONTENT LICENSE AGREEMENT</td>\n",
       "      <td>['YOU ON DEMAND HOLDINGS, INC.', 'Licensor', '...</td>\n",
       "      <td>Beijing Sun Seven Stars Culture Development Li...</td>\n",
       "      <td>['December 21, 2015']</td>\n",
       "      <td>12/21/15</td>\n",
       "      <td>['December 21, 2015']</td>\n",
       "      <td>12/21/15</td>\n",
       "      <td>['The Term of this Agreement (the \"Term\") shal...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
       "1  EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...   \n",
       "2  FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...   \n",
       "3  GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...   \n",
       "4  IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...   \n",
       "\n",
       "                                    Document Name  \\\n",
       "0               ['MARKETING AFFILIATE AGREEMENT']   \n",
       "1   ['VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT']   \n",
       "2  ['CONTENT DISTRIBUTION AND LICENSE AGREEMENT']   \n",
       "3           ['WEBSITE CONTENT LICENSE AGREEMENT']   \n",
       "4                   ['CONTENT LICENSE AGREEMENT']   \n",
       "\n",
       "                         Document Name-Answer  \\\n",
       "0               MARKETING AFFILIATE AGREEMENT   \n",
       "1   VIDEO-ON-DEMAND CONTENT LICENSE AGREEMENT   \n",
       "2  CONTENT DISTRIBUTION AND LICENSE AGREEMENT   \n",
       "3           WEBSITE CONTENT LICENSE AGREEMENT   \n",
       "4                   CONTENT LICENSE AGREEMENT   \n",
       "\n",
       "                                             Parties  \\\n",
       "0  ['BIRCH FIRST GLOBAL INVESTMENTS INC.', 'MA', ...   \n",
       "1  ['EuroMedia Holdings Corp.', 'Rogers', 'Rogers...   \n",
       "2  ['Producer', 'Fulucai Productions Ltd.', 'Conv...   \n",
       "3  ['PSiTech Corporation', 'Licensor', 'Licensee'...   \n",
       "4  ['YOU ON DEMAND HOLDINGS, INC.', 'Licensor', '...   \n",
       "\n",
       "                                      Parties-Answer  \\\n",
       "0  Birch First Global Investments Inc. (\"Company\"...   \n",
       "1  Rogers Cable Communications Inc. (\"Rogers\"); E...   \n",
       "2  CONVERGTV, INC. (“ConvergTV”); Fulucai Product...   \n",
       "3  PSiTech Corporation (\"Licensor\"); Empirical Ve...   \n",
       "4  Beijing Sun Seven Stars Culture Development Li...   \n",
       "\n",
       "                           Agreement Date Agreement Date-Answer  \\\n",
       "0  ['8th day of May 2014', 'May 8, 2014']                5/8/14   \n",
       "1                      ['July 11 , 2006']               7/11/06   \n",
       "2                   ['November 15, 2012']              11/15/12   \n",
       "3                        ['Feb 10, 2014']               2/10/14   \n",
       "4                   ['December 21, 2015']              12/21/15   \n",
       "\n",
       "                                      Effective Date Effective Date-Answer  \\\n",
       "0  ['This agreement shall begin upon the date of ...                   NaN   \n",
       "1                                 ['July 11 , 2006']               7/11/06   \n",
       "2                              ['November 15, 2012']              11/15/12   \n",
       "3                                   ['Feb 10, 2014']               2/10/14   \n",
       "4                              ['December 21, 2015']              12/21/15   \n",
       "\n",
       "                                     Expiration Date  ... Liquidated Damages  \\\n",
       "0  ['This agreement shall begin upon the date of ...  ...                 []   \n",
       "1  ['The term of this Agreement (the \"Initial Ter...  ...                 []   \n",
       "2                                                 []  ...                 []   \n",
       "3  ['The initial term of this Agreement commences...  ...                 []   \n",
       "4  ['The Term of this Agreement (the \"Term\") shal...  ...                 []   \n",
       "\n",
       "  Liquidated Damages-Answer  \\\n",
       "0                        No   \n",
       "1                        No   \n",
       "2                        No   \n",
       "3                        No   \n",
       "4                        No   \n",
       "\n",
       "                                   Warranty Duration Warranty Duration-Answer  \\\n",
       "0  [\"COMPANY'S SOLE AND EXCLUSIVE LIABILITY FOR T...                      Yes   \n",
       "1                                                 []                       No   \n",
       "2                                                 []                       No   \n",
       "3                                                 []                       No   \n",
       "4                                                 []                       No   \n",
       "\n",
       "  Insurance Insurance-Answer Covenant Not To Sue Covenant Not To Sue-Answer  \\\n",
       "0        []               No                  []                         No   \n",
       "1        []               No                  []                         No   \n",
       "2        []               No                  []                         No   \n",
       "3        []               No                  []                         No   \n",
       "4        []               No                  []                         No   \n",
       "\n",
       "  Third Party Beneficiary Third Party Beneficiary-Answer  \n",
       "0                      []                             No  \n",
       "1                      []                             No  \n",
       "2                      []                             No  \n",
       "3                      []                             No  \n",
       "4                      []                             No  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read master clauses CSV into a dataframe, sort by filename to match text file dataframe created above\n",
    "mc_df = pd.read_csv(MASTER_PATH+MASTER_CLAUSES)\n",
    "\n",
    "display(mc_df.head(5))\n",
    "# Cut out the relevant info\n",
    "mc_df_cut = mc_df[['Filename',\n",
    "                   'Document Name',\n",
    "                   'Document Name-Answer',\n",
    "                   'Parties',\n",
    "                   'Parties-Answer',\n",
    "                   'Agreement Date',\n",
    "                   'Agreement Date-Answer']].copy()\n",
    "\n",
    "# Sort the dataframe by filename\n",
    "mc_df_cut.sort_values('Filename', axis=0, inplace=True, ignore_index=True) \n",
    "\n",
    "# Bring in the list of the .txt filenames\n",
    "mc_df_cut.insert(loc=1, column='Text Files', value=tf_df)\n",
    "\n",
    "# Create a list of the names of the files, with index num\n",
    "file_list = [(index, row['Text Files']) for index, row in mc_df_cut.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 510 entries, 0 to 509\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Filename               510 non-null    object\n",
      " 1   Text Files             510 non-null    object\n",
      " 2   Document Name          510 non-null    object\n",
      " 3   Document Name-Answer   510 non-null    object\n",
      " 4   Parties                510 non-null    object\n",
      " 5   Parties-Answer         509 non-null    object\n",
      " 6   Agreement Date         510 non-null    object\n",
      " 7   Agreement Date-Answer  465 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 32.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Initial dataframe info\n",
    "mc_df_cut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean up and pre-process the text.\n",
    "# This process should be used for any document text inc. train, validation and test sets.\n",
    "def pre_process_doc_common(text):\n",
    "    # Simple replacement for \"\\n\"\n",
    "    text = text.replace(\"\\n\", \" \")     \n",
    "    \n",
    "    # Simple replacement for \"\\xa0\"\n",
    "    text = text.replace(\"\\xa0\", \" \")  \n",
    "    \n",
    "    # Simple replacement for \"\\x0c\"\n",
    "    text = text.replace(\"\\x0c\", \" \")\n",
    "    \n",
    "    # Get rid of multiple dots\n",
    "    regex = \"\\ \\.\\ \"\n",
    "    subst = \".\"\n",
    "    text = re.sub(regex, subst, text, 0)\n",
    "    \n",
    "    # Get rid of underscores\n",
    "    regex = \"_\"\n",
    "    subst = \" \"\n",
    "    text = re.sub(regex, subst, text, 0)\n",
    "    \n",
    "    # Get rid of multiple dashes\n",
    "    regex = \"--+\"\n",
    "    subst = \" \"\n",
    "    text = re.sub(regex, subst, text, 0)\n",
    "    \n",
    "    # Get rid of multiple stars\n",
    "    regex = \"\\*+\"\n",
    "    subst = \"*\"\n",
    "    text = re.sub(regex, subst, text, 0)\n",
    "    \n",
    "    # Get rid of multiple whitespace\n",
    "    regex = \"\\ +\"\n",
    "    subst = \" \"\n",
    "    text = re.sub(regex, subst, text, 0)\n",
    "    \n",
    "    #Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to take in the file list, read each file, clean the text and return all agreements in a list\n",
    "def text_data(file_list, print_text=False, clean_text=True, max_len=3000):\n",
    "    text_list = []\n",
    "    for index, filename in tqdm(file_list):\n",
    "        agreement = open(TC_PATH+filename, \"r\")\n",
    "        text = agreement.read()\n",
    "        if print_text:\n",
    "            print(\"Text before cleaning: \\n\", text)\n",
    "        \n",
    "        # Run text through cleansing function\n",
    "        if clean_text:\n",
    "            text = pre_process_doc_common(text)\n",
    "        text = text[:max_len]\n",
    "        len_text = len(text)\n",
    "        \n",
    "        if print_text:\n",
    "            print(\"Text after cleaning: \\n\", text)\n",
    "        \n",
    "        text_list.append([index,\n",
    "                  filename,\n",
    "                  text,\n",
    "                  len_text])\n",
    "        \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 510/510 [00:03<00:00, 144.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text Files</th>\n",
       "      <th>Document Name</th>\n",
       "      <th>Document Name-Answer</th>\n",
       "      <th>Parties</th>\n",
       "      <th>Parties-Answer</th>\n",
       "      <th>Agreement Date</th>\n",
       "      <th>Agreement Date-Answer</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length_Of_Text</th>\n",
       "      <th>Doc_N_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ThemartComInc_19990826_10-12G_EX-10.10_670028...</td>\n",
       "      <td>2ThemartComInc_19990826_10-12G_EX-10.10_670028...</td>\n",
       "      <td>[CO-BRANDING AND ADVERTISING AGREEMENT]</td>\n",
       "      <td>CO-BRANDING AND ADVERTISING AGREEMENT</td>\n",
       "      <td>[2THEMART.COM, INC., 2TheMart, i-Escrow, I-ESC...</td>\n",
       "      <td>I-ESCROW, INC.  (\"i-Escrow\" ); 2THEMART.COM, I...</td>\n",
       "      <td>[June 21, 1999]</td>\n",
       "      <td>6/21/99</td>\n",
       "      <td>CO-BRANDING AND ADVERTISING AGREEMENT THIS CO-...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEME...</td>\n",
       "      <td>ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEME...</td>\n",
       "      <td>[Services Agreement]</td>\n",
       "      <td>Services Agreement</td>\n",
       "      <td>[\"Provider\", TELCOSTAR PTE, LTD., Each of the ...</td>\n",
       "      <td>[ * * * ] (\"Provider\"); TELCOSTAR PTE, LTD.; A...</td>\n",
       "      <td>[October 1, 2019]</td>\n",
       "      <td>10/1/19</td>\n",
       "      <td>EXHIBIT 4.25 INFORMATION IN THIS EXHIBIT IDENT...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-...</td>\n",
       "      <td>ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-...</td>\n",
       "      <td>[JOINT VENTURE AGREEMENT]</td>\n",
       "      <td>JOINT VENTURE AGREEMENT</td>\n",
       "      <td>[Pivotal Self Service Tech, Inc., (the \"Partie...</td>\n",
       "      <td>Collectible Concepts Group, Inc. (\"CCGI\"); Piv...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXHIBIT 10.13 JOINT VENTURE AGREEMENT Collecti...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  2ThemartComInc_19990826_10-12G_EX-10.10_670028...   \n",
       "1  ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEME...   \n",
       "2  ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-...   \n",
       "\n",
       "                                          Text Files  \\\n",
       "0  2ThemartComInc_19990826_10-12G_EX-10.10_670028...   \n",
       "1  ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEME...   \n",
       "2  ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-...   \n",
       "\n",
       "                             Document Name  \\\n",
       "0  [CO-BRANDING AND ADVERTISING AGREEMENT]   \n",
       "1                     [Services Agreement]   \n",
       "2                [JOINT VENTURE AGREEMENT]   \n",
       "\n",
       "                    Document Name-Answer  \\\n",
       "0  CO-BRANDING AND ADVERTISING AGREEMENT   \n",
       "1                     Services Agreement   \n",
       "2                JOINT VENTURE AGREEMENT   \n",
       "\n",
       "                                             Parties  \\\n",
       "0  [2THEMART.COM, INC., 2TheMart, i-Escrow, I-ESC...   \n",
       "1  [\"Provider\", TELCOSTAR PTE, LTD., Each of the ...   \n",
       "2  [Pivotal Self Service Tech, Inc., (the \"Partie...   \n",
       "\n",
       "                                      Parties-Answer     Agreement Date  \\\n",
       "0  I-ESCROW, INC.  (\"i-Escrow\" ); 2THEMART.COM, I...    [June 21, 1999]   \n",
       "1  [ * * * ] (\"Provider\"); TELCOSTAR PTE, LTD.; A...  [October 1, 2019]   \n",
       "2  Collectible Concepts Group, Inc. (\"CCGI\"); Piv...                 []   \n",
       "\n",
       "  Agreement Date-Answer                                               Text  \\\n",
       "0               6/21/99  CO-BRANDING AND ADVERTISING AGREEMENT THIS CO-...   \n",
       "1               10/1/19  EXHIBIT 4.25 INFORMATION IN THIS EXHIBIT IDENT...   \n",
       "2                   NaN  EXHIBIT 10.13 JOINT VENTURE AGREEMENT Collecti...   \n",
       "\n",
       "   Length_Of_Text  Doc_N_Length  \n",
       "0            1000             1  \n",
       "1            1000             1  \n",
       "2            1000             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text and create dataframe with the text of ech document\n",
    "data = text_data(file_list, print_text=False, clean_text=True, max_len=1000)\n",
    "columns = ['ID', 'Documents', 'Text', 'Length_Of_Text']\n",
    "text_df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "# Add the two columns to a copy of the main dataframe\n",
    "mc_df_wk = mc_df_cut.copy()\n",
    "mc_df_wk = mc_df_wk.join(text_df[['Text', 'Length_Of_Text']])\n",
    "\n",
    "#Ensure agreement date, doc_name and parties are list objects\n",
    "mc_df_wk[\"Agreement Date\"] = mc_df_wk[\"Agreement Date\"].apply(eval)\n",
    "mc_df_wk[\"Document Name\"] = mc_df_wk[\"Document Name\"].apply(eval)\n",
    "mc_df_wk[\"Parties\"] = mc_df_wk[\"Parties\"].apply(eval)\n",
    "\n",
    "# Some document name references have more than one entry - remove them for further inspection later\n",
    "mc_df_wk['Doc_N_Length'] = mc_df_wk['Document Name'].str.len()\n",
    "mc_df_mul = mc_df_wk[mc_df_wk.Doc_N_Length > 1]\n",
    "mc_df_wk.drop(mc_df_mul.index, inplace=True)\n",
    "\n",
    "# Have a look at the data\n",
    "mc_df_wk.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 499 entries, 0 to 509\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Filename               499 non-null    object\n",
      " 1   Text Files             499 non-null    object\n",
      " 2   Document Name          499 non-null    object\n",
      " 3   Document Name-Answer   499 non-null    object\n",
      " 4   Parties                499 non-null    object\n",
      " 5   Parties-Answer         498 non-null    object\n",
      " 6   Agreement Date         499 non-null    object\n",
      " 7   Agreement Date-Answer  458 non-null    object\n",
      " 8   Text                   499 non-null    object\n",
      " 9   Length_Of_Text         499 non-null    int64 \n",
      " 10  Doc_N_Length           499 non-null    int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 46.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "mc_df_wk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 458 entries, 0 to 509\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Filename               458 non-null    object\n",
      " 1   Text Files             458 non-null    object\n",
      " 2   Document Name          458 non-null    object\n",
      " 3   Document Name-Answer   458 non-null    object\n",
      " 4   Parties                458 non-null    object\n",
      " 5   Parties-Answer         458 non-null    object\n",
      " 6   Agreement Date         458 non-null    object\n",
      " 7   Agreement Date-Answer  458 non-null    object\n",
      " 8   Text                   458 non-null    object\n",
      " 9   Length_Of_Text         458 non-null    int64 \n",
      " 10  Doc_N_Length           458 non-null    int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 42.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Agreement date is an important label. Here we will drop any agreement without a date.\n",
    "# These will typically be template or specimen agreements which havent been executed\n",
    "# Prior to dropping, we create a dataframe to manually check and annotate agreement date in a different exercise\n",
    "mc_df_nul = mc_df_wk[mc_df_wk[\"Agreement Date-Answer\"].isnull()]\n",
    "mc_df_wk = mc_df_wk.dropna(subset=['Agreement Date-Answer'])\n",
    "mc_df_wk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CUADv1 labels includes the Party definition eg Apple Inc. \"Apple\", here we keep just the legal entity:\n",
    "def remove_party_overlaps(labels):\n",
    "    labels.sort()\n",
    "    k = []\n",
    "    for i in range(len(labels)-1):\n",
    "        l1 = labels[i]\n",
    "        l2 = labels[i+1]\n",
    "        if l1[0] == l2[0]:\n",
    "            len1 = l1[1] - l1[0]\n",
    "            len2 = l2[1] - l2[0]\n",
    "            if len1 > len2:\n",
    "                k.append(l1)\n",
    "                continue\n",
    "            else:\n",
    "                k.append(l2)\n",
    "                continue\n",
    "        else:\n",
    "            k.append(labels[i])\n",
    "    new_labels = list(k for k,_ in itertools.groupby(k))\n",
    "    \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "458it [00:00, 702.62it/s]\n",
      "11it [00:00, 4008.46it/s]\n",
      "41it [00:00, 3544.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Go through each label and find the label in the text, ensure label is pre-processed same as text.\n",
    "# If labels don't match, append to a seperate file to check.\n",
    "\n",
    "clean_text = True\n",
    "djson = list()\n",
    "djson_inspect = list()\n",
    "for index, row in tqdm(mc_df_wk.iterrows()):\n",
    "    labels = list()\n",
    "    ids = index\n",
    "    text = row['Text']\n",
    "    \n",
    "    #DOC_NAME\n",
    "    doc_names = row['Document Name']\n",
    "    for name in doc_names:\n",
    "        if clean_text:\n",
    "            name = pre_process_doc_common(name)\n",
    "        matches = re.finditer(re.escape(name.lower()), text.lower())\n",
    "        for m in matches:\n",
    "            s = m.start()\n",
    "            e = m.end()\n",
    "            labels.append([s, e, 'DOC_NAME'])\n",
    "    \n",
    "    #AGMT_DATE\n",
    "    agmt_date = row['Agreement Date']\n",
    "    for date in agmt_date:\n",
    "        if clean_text:\n",
    "            date = pre_process_doc_common(date)\n",
    "        matches = re.finditer(re.escape(date.lower()), text.lower())\n",
    "        for m in matches:\n",
    "            s = m.start()\n",
    "            e = m.end()\n",
    "            labels.append([s, e, 'AGMT_DATE'])\n",
    "\n",
    "    #PARTIES\n",
    "    parties = row['Parties']\n",
    "    for party in parties:\n",
    "        if clean_text:\n",
    "            party = pre_process_doc_common(party)\n",
    "        matches = re.finditer(re.escape(party.lower()), text.lower())\n",
    "        for m in matches:\n",
    "            s = m.start()\n",
    "            e = m.end()\n",
    "            labels.append([s, e, 'PARTY'])\n",
    "    \n",
    "    labels = remove_party_overlaps(labels)\n",
    "    #print(labels)\n",
    "    \n",
    "    # Check for incongruous finds, add to inspect file\n",
    "    flat_list = [item for sublist in labels for item in sublist]\n",
    "    if 'DOC_NAME' in flat_list and 'AGMT_DATE' in flat_list and 'PARTY' in flat_list:\n",
    "        djson.append({'id': ids, 'text': text, \"labels\": labels})\n",
    "    else:\n",
    "        djson_inspect.append({'id': ids, 'text': text, \"labels\": labels})\n",
    "\n",
    "# Add to the check JSON file the other documents excluded due to duplicate names and no agreement dates\n",
    "for index, row in tqdm(mc_df_mul.iterrows()):\n",
    "    labels = list()\n",
    "    ids = index\n",
    "    text = row['Text']\n",
    "    djson_inspect.append({'id': ids, 'text': text, \"labels\": labels})\n",
    "\n",
    "for index, row in tqdm(mc_df_nul.iterrows()):\n",
    "    labels = list()\n",
    "    ids = index\n",
    "    text = row['Text']\n",
    "    djson_inspect.append({'id': ids, 'text': text, \"labels\": labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are left with 353 training samples out of 510 to annotate.\n",
      "Additional agreements to check:  157\n"
     ]
    }
   ],
   "source": [
    "# The process above requires the three label types to be present in each agreement extract. This may not\n",
    "# be the case due to the shortening of the agreememt for example. Let's check how many we are left with\n",
    "# and how many we need to manually check...\n",
    "print(f\"We are left with {len(djson)} training samples out of 510 to annotate.\")\n",
    "print(\"Additional agreements to check: \",len(djson_inspect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for erroneous labels\n",
    "count = 0\n",
    "for n in range(len(djson)):\n",
    "    labs = djson[n]['labels']\n",
    "    flat_list = [item for sublist in labs for item in sublist]\n",
    "    if -1 in flat_list:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179314"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the full datasets for import to Doccano\n",
    "filepath = JSON_EXPORT\n",
    "open(filepath, 'w').write(\"\\n\".join([json.dumps(e) for e in djson]))\n",
    "\n",
    "filepath = JSON_EXPORT_INSPECT\n",
    "open(filepath, 'w').write(\"\\n\".join([json.dumps(e) for e in djson_inspect]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Doccano to tag the text file dataset:\n",
    " - Install doccano at the command line: pip install doccano\n",
    " - At the command line change the directory to this directory\n",
    " - run doccano at the command line by typing 'doccano'\n",
    " - Application will be running at http://0.0.0.0:8000/\n",
    " - Username is 'admin', passowrd is 'password'\n",
    " - Use ctrl-c to end application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
